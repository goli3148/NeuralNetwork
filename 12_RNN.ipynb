{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\__init__.py:1633\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_library\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m \u001b[38;5;66;03m# quantization depends on torch.fx\u001b[39;00m\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;66;03m# Import quantization\u001b[39;00m\n\u001b[1;32m-> 1633\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization \u001b[38;5;28;01mas\u001b[39;00m quantization\n\u001b[0;32m   1635\u001b[0m \u001b[38;5;66;03m# Import the quasi random sampler\u001b[39;00m\n\u001b[0;32m   1636\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quasirandom \u001b[38;5;28;01mas\u001b[39;00m quasirandom\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\quantization\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mqconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\quantization\\quantize.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa: F401\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mis kept here for compatibility while the migration process is ongoing.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mhere.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     _add_observer_,\n\u001b[0;32m     12\u001b[0m     _convert,\n\u001b[0;32m     13\u001b[0m     _get_observer_dict,\n\u001b[0;32m     14\u001b[0m     _get_unique_devices_,\n\u001b[0;32m     15\u001b[0m     _is_activation_post_process,\n\u001b[0;32m     16\u001b[0m     _observer_forward_hook,\n\u001b[0;32m     17\u001b[0m     _propagate_qconfig_helper,\n\u001b[0;32m     18\u001b[0m     _register_activation_post_process_hook,\n\u001b[0;32m     19\u001b[0m     _remove_activation_post_process,\n\u001b[0;32m     20\u001b[0m     _remove_qconfig,\n\u001b[0;32m     21\u001b[0m     add_quant_dequant,\n\u001b[0;32m     22\u001b[0m     convert,\n\u001b[0;32m     23\u001b[0m     prepare,\n\u001b[0;32m     24\u001b[0m     prepare_qat,\n\u001b[0;32m     25\u001b[0m     propagate_qconfig_,\n\u001b[0;32m     26\u001b[0m     quantize,\n\u001b[0;32m     27\u001b[0m     quantize_dynamic,\n\u001b[0;32m     28\u001b[0m     quantize_qat,\n\u001b[0;32m     29\u001b[0m     swap_module,\n\u001b[0;32m     30\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\ao\\quantization\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flake8: noqa: F403\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_quantize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuse_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuse_modules  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfuse_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fuse_modules_qat  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\ao\\quantization\\fake_quantize.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     MovingAverageMinMaxObserver,\n\u001b[0;32m      7\u001b[0m     HistogramObserver,\n\u001b[0;32m      8\u001b[0m     MovingAveragePerChannelMinMaxObserver,\n\u001b[0;32m      9\u001b[0m     FixedQParamsObserver,\n\u001b[0;32m     10\u001b[0m     default_fixed_qparams_range_0to1_observer,\n\u001b[0;32m     11\u001b[0m     default_fixed_qparams_range_neg1to1_observer,\n\u001b[0;32m     12\u001b[0m     _with_args,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ABC, abstractmethod\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\ao\\quantization\\observer.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     check_min_max_valid, calculate_qmin_qmax, is_per_tensor, is_per_channel, validate_qmin_qmax)\n\u001b[0;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_affine_fixed_qparams_observer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_debug_observer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniformQuantizationObserverBase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     49\u001b[0m ]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_PartialWrapper\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\ao\\quantization\\utils.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mao\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquant_type\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuantType\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparametrize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_parametrized\n\u001b[0;32m     15\u001b[0m NodePattern \u001b[38;5;241m=\u001b[39m Union[Tuple[Node, Node], Tuple[Node, Tuple[Node, Node]], Any]\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\fx\\__init__.py:83\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mFX is a toolkit for developers to use to transform ``nn.Module``\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03minstances. FX consists of three main components: a **symbolic tracer,**\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03mrepository.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphModule\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_symbolic_trace\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m symbolic_trace, Tracer, wrap, PH, ProxyableClassMeta\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Graph, CodeGen\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\fx\\graph_module.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Importer, PackageExporter, PackageImporter, sys_importer\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatibility\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _custom_builtins, _is_from_torch, _PyTreeCodeGen, Graph, PythonCode\n\u001b[0;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce_graph_module\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce_package_graph_module\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce_deploy_graph_module\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m ]\n\u001b[0;32m     28\u001b[0m _USER_PRESERVED_ATTRIBUTES_KEY \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_user_preserved_attributes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\fx\\graph.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Node, Argument, Target, map_arg, _type_repr, _get_qualified_name\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpytree\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pytree \u001b[38;5;28;01mas\u001b[39;00m fx_pytree\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compatibility\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compatibility\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\fx\\_pytree.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, NamedTuple, Optional, Tuple, Type\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreturn_types\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyTree, TreeSpec\n\u001b[0;32m      8\u001b[0m FlattenFuncSpec \u001b[38;5;241m=\u001b[39m Callable[[PyTree, TreeSpec], List]\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\return_types.py:48\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Today everything in torch.return_types is a structseq, aka a \"namedtuple\"-like\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# thing defined by the Python C-API. We're going to need to modify this when that\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# is no longer the case.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# NB: I don't know how to check that something is a \"structseq\" so we do a fuzzy\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# check for tuple\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misclass(_attr) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(_attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m---> 48\u001b[0m     \u001b[43mpytree_register_structseq\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_attr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\return_types.py:24\u001b[0m, in \u001b[0;36mpytree_register_structseq\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructseq_unflatten\u001b[39m(values, context):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(values)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mregister_pytree_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstructseq_flatten\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstructseq_unflatten\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflatten_with_keys_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructseq_flatten_with_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\utils\\_pytree.py:210\u001b[0m, in \u001b[0;36mregister_pytree_node\u001b[1;34m(cls, flatten_fn, unflatten_fn, serialized_type_name, to_dumpable_context, from_dumpable_context, flatten_with_keys_fn)\u001b[0m\n\u001b[0;32m    199\u001b[0m _private_register_pytree_node(\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    201\u001b[0m     flatten_fn,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     flatten_with_keys_fn\u001b[38;5;241m=\u001b[39mflatten_with_keys_fn,\n\u001b[0;32m    207\u001b[0m )\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cxx_pytree \u001b[38;5;28;01mas\u001b[39;00m cxx\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1322\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1528\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1502\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1601\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchvision import transforms\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mr.J\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mr.J\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mr.J\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED  = 123\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "max_sequence    = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style/Size:</th>\n",
       "      <th>style/Color:</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>style/Size Name:</th>\n",
       "      <th>style/Style:</th>\n",
       "      <th>vote</th>\n",
       "      <th>image/0</th>\n",
       "      <th>image/1</th>\n",
       "      <th>image/2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>Big Boys</td>\n",
       "      <td>Blue/Orange</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>Big Boys</td>\n",
       "      <td>Black (37467610) / Red/White</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>Big Boys</td>\n",
       "      <td>Blue/Gray Logo</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>Big Boys</td>\n",
       "      <td>Blue (37867638-99) / Yellow</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>Big Boys</td>\n",
       "      <td>Blue/Pink</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified  reviewTime     reviewerID        asin style/Size:  \\\n",
       "0        5      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K    Big Boys   \n",
       "1        5      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K    Big Boys   \n",
       "2        5      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K    Big Boys   \n",
       "3        5      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K    Big Boys   \n",
       "4        5      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K    Big Boys   \n",
       "\n",
       "                    style/Color: reviewerName                reviewText  \\\n",
       "0                    Blue/Orange     Tonya B.  Great product and price!   \n",
       "1   Black (37467610) / Red/White     Tonya B.  Great product and price!   \n",
       "2                 Blue/Gray Logo     Tonya B.  Great product and price!   \n",
       "3    Blue (37867638-99) / Yellow     Tonya B.  Great product and price!   \n",
       "4                      Blue/Pink     Tonya B.  Great product and price!   \n",
       "\n",
       "      summary  unixReviewTime style/Size Name: style/Style:  vote image/0  \\\n",
       "0  Five Stars      1441324800              NaN          NaN   NaN     NaN   \n",
       "1  Five Stars      1441324800              NaN          NaN   NaN     NaN   \n",
       "2  Five Stars      1441324800              NaN          NaN   NaN     NaN   \n",
       "3  Five Stars      1441324800              NaN          NaN   NaN     NaN   \n",
       "4  Five Stars      1441324800              NaN          NaN   NaN     NaN   \n",
       "\n",
       "  image/1 image/2  \n",
       "0     NaN     NaN  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3     NaN     NaN  \n",
       "4     NaN     NaN  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('dataset/IMDB Dataset.csv')\n",
    "df = pd.read_csv('dataset/AMAZON_FASHION_5.csv')\n",
    "df = df.dropna(subset=['reviewText'])\n",
    "# df = df.sample(frac=1, random_state=1)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    if isinstance(text, float):\n",
    "        print(text)\n",
    "    return text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "def remove_stop_words(tokens):\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "def lemmatize_words(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df['reviewText'].apply(remove_punctuation).apply(word_tokenize).apply(remove_stop_words).apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(sentiment):\n",
    "    return sentiment-1\n",
    "\n",
    "# def map_sentiment(sentiment):\n",
    "#     if sentiment == 'positive':\n",
    "#         return 1\n",
    "#     return 0\n",
    "\n",
    "# Apply the mapping function to the 'sentiment' column\n",
    "sentiment = df['overall'].apply(map_sentiment)\n",
    "# sentiment = df['sentiment'].replace({\"positive\":[1,0], \"negative\":[0,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3160\n",
      "3160\n"
     ]
    }
   ],
   "source": [
    "X = review.to_list()\n",
    "y = sentiment[review.index].to_numpy()\n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [token for phrase in X  for token in phrase ]\n",
    "vocab = Counter(all_words)\n",
    "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
    "encoded_review = [[vocab_to_int[token] for token in phrase] for phrase in X]\n",
    "\n",
    "\n",
    "\n",
    "features = np.zeros((len(encoded_review), max_sequence), dtype=np.int32)\n",
    "for i, e in enumerate(encoded_review):\n",
    "    e_len = len(e)\n",
    "    if e_len <= max_sequence:\n",
    "        zeros   = list(np.zeros(max_sequence-e_len))\n",
    "        new     = zeros + e\n",
    "    else:\n",
    "        new     = e[:max_sequence]\n",
    "    features[i,:] = np.array(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imdbdataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None, exclude_type=None) -> None:\n",
    "        super(imdbdataset, self).__init__()\n",
    "        if exclude_type==\"train\":\n",
    "            mask = np.isin(y, list(set([1,3])), invert=True)\n",
    "            self.x = x[mask]\n",
    "            y = y[mask]\n",
    "            y = np.where(y==0, 0, y)\n",
    "            y = np.where(y==2, 2, y)\n",
    "            y = np.where(y==4, 3, y)\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.x = x\n",
    "            self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    # def get_labels(self):   return self.y\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        x = np.array(x) if not isinstance(x, np.ndarray) else x\n",
    "        y = np.array(y) if not isinstance(y, np.ndarray) else y\n",
    "        return torch.from_numpy(x), torch.from_numpy(y).long()\n",
    "\n",
    "compose = transforms.Compose([\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "train_data_set = imdbdataset(x_train, y_train, transform=compose, exclude_type='train')\n",
    "test_data_set  = imdbdataset(x_test,  y_test,  transform=compose, exclude_type='train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data_set, batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(test_data_set,  batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   6 108 106]\n",
      " [  0   0   0 ...   6 108 106]\n",
      " [  0   0   0 ...   6 108 106]\n",
      " ...\n",
      " [  0   0   0 ...   4   3  14]\n",
      " [  0   0   0 ...  16  87  57]\n",
      " [  0   0   0 ...  35  41 155]] tensor([3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 2, 0, 3])\n"
     ]
    }
   ],
   "source": [
    "example = iter(train_loader)\n",
    "feature, label = next(example)\n",
    "print(features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, rnn_type='simple'):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding  = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn        = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn        = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        else:\n",
    "            self.rnn        = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        self.fc         = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, tt):\n",
    "        embedded = self.embedding(tt)\n",
    "\n",
    "        out, h = self.rnn(embedded)\n",
    "\n",
    "        if self.rnn_type == 'lstm':\n",
    "            h = h[0]\n",
    "\n",
    "        output = self.fc(h.squeeze_(0))\n",
    "        return output\n",
    "\n",
    "learning_rate   = .001\n",
    "num_epochs      = 3\n",
    "embedding_dim   = 100\n",
    "hidden_dim      = 128\n",
    "num_classes     = 3\n",
    "\n",
    "\n",
    "model = RNN(input_dim=len(vocab_to_int)+1, embedding_dim=embedding_dim, \n",
    "            hidden_dim=hidden_dim, output_dim=num_classes, rnn_type='simple').to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(class_test=False):    \n",
    "    test_loss   = 0.0\n",
    "    total       = 0\n",
    "    correct     = 0\n",
    "    n_class_correct = [0 for i in range(num_classes)]\n",
    "    n_class_samples = [0 for i in range(num_classes)]\n",
    "    with torch.no_grad():\n",
    "        for text, label in test_loader:\n",
    "            text, label = text.to(device), label.to(device)\n",
    "            output = model(text)\n",
    "            loss = criterion(output, label)\n",
    "            test_loss += loss.item() * text.size(0)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "            for i in range(len(label)):\n",
    "                label_ = label[i]\n",
    "                pred  = predicted[i]\n",
    "                if (label_ == pred):\n",
    "                    n_class_correct[label_] += 1\n",
    "                n_class_samples[label_] += 1\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    print(f\" Test Loss: {test_loss}, Test Accuracy: {accuracy}\")\n",
    "    if class_test:\n",
    "        for i in range(num_classes):\n",
    "            acc = 100 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {i}:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unique_by_key: failed to synchronize: cudaErrorInvalidValue: invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m l \u001b[38;5;241m=\u001b[39m criterion(output, label)\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()    \n\u001b[0;32m     16\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m l\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mr.J\\.conda\\envs\\neuralnetwork\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: unique_by_key: failed to synchronize: cudaErrorInvalidValue: invalid argument"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for text, label in train_loader:\n",
    "        text, label = text.to(device), label.to(device)\n",
    "\n",
    "        output = model(text)\n",
    "\n",
    "        l = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        l.backward()\n",
    "\n",
    "        optimizer.step()    \n",
    "\n",
    "        train_loss += l.item()\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f\"epoch {epoch+1}/{num_epochs} loss: {train_loss}\", end='')\n",
    "    test()\n",
    "test(class_test=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
